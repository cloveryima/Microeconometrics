wald.test(b = coef(myprobit2), Sigma = vcovHC(m, type = "const"), L = mR, H0 = vR)
myprobit2 <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60 + pcnvsq + pt86sq + inc86sq, data = grogger)
summary(myprobit2)
wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2, type = "const"), L = mR, H0 = vR)
vR <- c(0, 0, 0)
mR <- as.matrix(rbind(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0),
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0),
c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)))
wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2, type = "const"), L = mR, H0 = vR)
sink("output8.txt")
print(wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2, type = "const"), L = mR, H0 = vR))
sink()
myprobit2 <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60 + pcnvsq + pt86sq + inc86sq, data = grogger)
summary(myprobit2)
coefficients$myprobit
#Import the data
getwd()
load(grogger.rda)
load("grogger.rda")
View(grogger)
# Create a dummy
is.numeric(grogger$narr86)
# Create a dummy
is.numeric(grogger$narr86 >=1)
# Create a dummy
is.numeric(grogger$narr86 >= 1)
# Create a dummy
is.numeric(grogger$narr86 %in% c(1:12))
# Create a dummy
a <- is.numeric(grogger$narr86 %in% c(1:12))
a
# Create a dummy
a <- as.numeric(grogger$narr86 %in% c(1:12))
# Create a dummy
grogger$arr86 <- as.numeric(grogger$narr86 %in% c(1:12))
remove(a)
library(foreign)
install.packages("lmtest")
library(lmtest)
install.packages("sandwich")
library(sandwich)
install.packages("lmtest")
# Linear Probability Model Estimation
lm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60, data = grogger)
# Linear Probability Model Estimation
lpm <- lm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60, data = grogger)
# Report the result
coeftest(lpm, vcov = vcovHC(lpm, type = "const"))
library(foreign)
install.packages("lmtest")
library(lmtest)
install.packages("sandwich")
library(sandwich)
# Report the result
coeftest(lpm, vcov = vcovHC(lpm, type = "const"))
sink("lpm_usual.txt")
print(coeftest(lpm, vcov = vcovHC(lpm, type = "const")))
sink()
coeftest(lpm, vcov = vcovHC(lpm, type = "HC"))
sink("lpm_usual.txt")
print(coeftest(lpm, vcov = vcovHC(lpm, type = "const")), coeftest(lpm, vcov = vcovHC(lpm, type = "HC")))
sink()
print(coeftest(lpm, vcov = vcovHC(lpm, type = "const")), coeftest(lpm, vcov = vcovHC(lpm, type = "HC")))
sink("lpm_robust.txt")
print(coeftest(lpm, vcoc = vcocHC(lpm, type = "HC")))
sink()
result_a = list.files("lpm_usual.txt", "lpm_robust.txt")
remove(result_a)
sink("lpm_usual.txt")
print(coeftest(lpm, vcov = vcovHC(lpm, type = "const")))
sink()
coeftest(lpm, vcov = vcovHC(lpm, type = "const")
# Report the result
coeftest(lpm, vcov = vcovHC(lpm, type = "const"))
coeftest(lpm, vcov = vcovHC(lpm, type = "const"))
0.5*(-.15438020)
install.packages("aod")
library(aod)
require(stats)
# Select the two variables avgsen and tottime
coef(lpm)
testcoef <-
as.matrix(c(0,0,1))
testcoef <-
is.matrix(c(0,0,1))
testcoef <-
matrix(c(0,0,1))
testcoef <-
matrix(rbind(c(0,0,1), c(1,1,1)))
testcoef <-
a <- matrix(rbind(c(0,0,1), c(1,1,1)))
a
testcoef <-
a <- matrix(c(0,0,1), c(1,1,1))
a
remove(a)
cbind(c(0,0,1),c(1,1,1))
testcoef <-
a <- cbind(c(0,0,1),c(1,1,1))
a
testcoef <-
a <- rbind(c(0,0,1),c(1,1,1))
a
testcoef <- as.matrix(rbind(c(0,0,1,0,0,0,0,0,0),c(0,0,0,1,0,0,0,0,0)))
null <- c(0,0)
null
testcoef
# Wald test
wald.test(Sigma = vcovHC(lpm, type = "const"), b = coef(lmp), L = testcoef, H0 = null)
# Wald test
wald.test(Sigma = vcovHC(lpm, type = "const"), b = coef(lpm), L = testcoef, H0 = null)
sink()
sink("waldtest.txt")
print(wald.test(Sigma = vcovHC(lpm, type = "const"), b = coef(lpm), L = testcoef, H0 = null))
sink()
sink("waldtest_non.txt")
print(wald.test(Sigma = vcovHC(lpm, type = "const"), b = coef(lpm), L = testcoef, H0 = null))
sink() #nonrobust
sink("waldtest_rbst.txt")
print(wald.test(Sigma = vcovHC(lpm, type = "HC"), b = coef(lpm), L = testcoef, H0 = null))
sink() #robust
require(aod)
install.packages("mfx")
library(mfx)
# Pobit model
myprobit <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born69, data = grogger)
# Pobit model
myprobit <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60, data = grogger)
fitted(myprobit)
# Part d
# Generate fitted values
predicted <- fitted(myprobit)
predicted >= .5
predictedarr <- as.numeric(predicted >= .5)
predictedarr
# Tabulate the fitted values agains the actual data
table(predictedarr, grogger$arr86)
# Tabulate the fitted values agains the actual data
table(predicted, grogger$arr86)
# Tabulate the fitted values agains the actual data
table(predictedarr, grogger$arr86)
table(predictedarr,grogger$arr86, grogger$narr86)
sink("predicted.txt")
print(table(predictedarr, grogger$arr86))
sink()
sink("predicted.txt")
print(table(predictedarr, grogger$arr86))
sink()
remove(a)
# Part e
# New probit model
myprobit2 <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60 + pcnvsq + pt86sq + inc86sq, data = grogger)
null1 <- c(0,0,0)
testcoef1 <- as.matrix(rbind(c(0,0,0,0,0,0,0,0,0,1,0,0)
c(0,0,0,0,0,0,0,0,0,0,1,0)
c(0,0,0,0,0,0,0,0,0,0,0,1)))
null1 <- c(0,0,0)
testcoef1 <- as.matrix(rbind(c(0,0,0,0,0,0,0,0,0,1,0,0),
c(0,0,0,0,0,0,0,0,0,0,1,0),
c(0,0,0,0,0,0,0,0,0,0,0,1)))
null2 <- c(0,0,0)
testcoef2 <- as.matrix(rbind(c(0,0,0,0,0,0,0,0,0,1,0,0),
c(0,0,0,0,0,0,0,0,0,0,1,0),
c(0,0,0,0,0,0,0,0,0,0,0,1)))
remove(null1)
remove(null2)
remove(testcoef2)
remove(testcoef1)
null2 <- c(0,0,0)
testcoef2 <- as.matrix(rbind(c(0,0,0,0,0,0,0,0,0,1,0,0),
c(0,0,0,0,0,0,0,0,0,0,1,0),
c(0,0,0,0,0,0,0,0,0,0,0,1)))
# Wald test
wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2), L = testcoef2, H0 = null2)
wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2, type = "const"), L = testcoef2, H0 = null2)
sink()
sink()
sink("waldtest2.txt")
wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2, type = "const"), L = testcoef2, H0 = null2)
sink()
# Test for individual significance
coef(myprobit2)
# Test for individual significance
summary(myprobit2)
coeftest(myprobit2)
sink("mypobit2.txt")
print(coeftest(myprobit2))
sink()
coeftest(myprobit2)
2*-2.4569e-01
7.5977e-02/(-0.49138)
7.5977e-02
7.5977e-02/(-0.49138)
coeftest(myprobit)
sink("myprobit.txt")
print(coeftest(myprobit))
sink()
# Report the result
coeftest(lpm, vcovHC, type = "const")
coeftest(lpm, vcov = vcovHC(lpm, type = "const"))
coeftest(lpm, vcovHC, type = "HC0")
coeftest(lpm, vcov = vcovHC(lpm, type = "HC"))
# Quesiton 1. Poison distribution
# Part a, b, and c are in the pdf
# Part d
read.csv("hw4.1.csv", header = TRUE)
# Quesiton 1. Poison distribution
# Part a, b, and c are in the pdf
# Part d
mydata <- read.csv("hw4.1.csv", header = TRUE)
View(mydata)
y <- mydata$y
View(mydata)
View(mydata)
y
# Part d
uniquevalues <- unique(y)
uniquevalues <- sort(uniquevalues)
uniquevalues
prob <- integer(12) #generate a numeric vector of size 12
for (i in 1:12){
prob[i] <- length(y[ which(y == uniquevalues[i])])/1000
}
prob
myfun1 <- function(theta){
result1 <- 0
for (i in 1:12){
result1 <- result1 - prob[i]*(uniquevalues[i]*log(theta) - theta - log(factorial(uniquevalues[i])))
}
return(result1)
}
# Empirical log-likelihood for the first observation
myfun2 <- function(theta){
result2 <- prob[6]*(5*log(theta)-theta-log(factorial(5)))
return(result2)
}
# Empirical log-likelihood for the second observation
myfun3 <- function(theta){
result3 <- prob[3]*(2*log(theta)-theta-log(factorial(2)))
return(result3)
}
# Plotting
ellf <- integer(10000) #expected likelihood function
elff <- integer(10000) #likelihood of the first observation
elfs <- integer(10000) # likelihood of the second observation
index <- integer(10000)
for (i in 1:10000){
ellf[i] <- (-1)*myfun1(i/1000) #because it would minimize if we don't use negative one
elff[i] <- myfun2(i/1000)
elfs[i] <- myfun3(i/1000)
index[i] <- i/1000
}
par(mfrow=c(1,3))
plot(index, ellf, main = "Empirical log-likelihood function", xlab = "theta", ylab  ="")
plot(index, elff, main = "Log-likelihood function for the first observation (5)", xlab = "theta", ylab ="", col = "blue")
plot(index, elfs, main = "Log-likelihood function for the second observation (2)", xlab = "theta", ylab ="", col = "red")
# 1.h
optimal <- optim(1,myfun1)
optimizer <- optimal$par
mean(y)
meany <- mean(y)
# 1.h
optimal <- optim(mean(y),myfun1)
optimizer <- optimal$par
mean(grogger)
summary(grogger)
remove(unquevalues)
remove(uniquevalues)
# Part d
uniquey <- unique(y)
uniquey <- sort(uniquevalues) #obtain all the values that y can take on
uniquey # there are 12 unique values
uniquey <- sort(uniquevalues) #obtain all the values that y can take on
uniquey <- sort(uniquey) #obtain all the values that y can take on
uniquey # there are 12 unique values
prob <- integer(12) #generate a numeric vector of size 12
for (i in 1:12){
prob[i] <- length(y[ which(y == uniquey[i])])/1000
}
prob
optimal <- optim(mean(y),myfun1)
optimizer <- optimal$par
myfun1 <- function(theta){
result1 <- 0
for (i in 1:12){
result1 <- result1 - prob[i]*(uniquey[i]*log(theta) - theta - log(factorial(uniquey[i])))
}
return(result1)
}
myfun2 <- function(theta){
result2 <- prob[6]*(5*log(theta)-theta-log(factorial(5)))
return(result2)
}
myfun3 <- function(theta){
result3 <- prob[3]*(2*log(theta)-theta-log(factorial(2)))
return(result3)
}
ellf <- integer(10000) #expected likelihood function
elff <- integer(10000) #likelihood of the first observation
elfs <- integer(10000) # likelihood of the second observation
index <- integer(10000)
for (i in 1:10000){
ellf[i] <- (-1)*myfun1(i/1000) #because it would minimize if we don't use negative one
elff[i] <- myfun2(i/1000)
elfs[i] <- myfun3(i/1000)
index[i] <- i/1000
}
par(mfrow=c(1,3))
plot(index, ellf, main = "Empirical log-likelihood function", xlab = "theta", ylab  ="")
plot(index, elff, main = "Log-likelihood function for the first observation (5)", xlab = "theta", ylab ="", col = "blue")
plot(index, elfs, main = "Log-likelihood function for the second observation (2)", xlab = "theta", ylab ="", col = "red")
optimal <- optim(mean(y),myfun1)
optimizer <- optimal$par
optimal <- optim(mean(y),myfun1)
optimizer <- optimal$par
optimizer
mean(y)
plot(index, ellf, main = "Empirical log-likelihood function", xlab = "theta", ylab  ="")
plot(index, elff, main = "Log-likelihood function for the first observation (5)", xlab = "theta", ylab ="", col = "blue")
plot(index, elfs, main = "Log-likelihood function for the second observation (2)", xlab = "theta", ylab ="", col = "red")
coeftest(myprobit)
summmary(grogger$avgsen, grogger$tottime, grogger$ptime86, grogger$inc86)
summmary(grogger$avgsen)
summary(grogger$avgsen)
summary(grogger$avgsen, grogger$totime, grgger$ptime86, grogger$inc86)
summary(grogger$avgsen, grogger$totime, grgger$ptime86, grogger$inc86)
summary(grogger$avgsen)
summary(grogger$tottime)
summary(grogger$ptime86)
summary(grogger$inc86)
summary(grogger$avgsen)
summary(grogger$tottime)
summary(grogger$ptime86)
summary(grogger$inc86)
#get the coefficient
coeftest(myprobit)
#get the average
summary(grogger)
# Marginal effects
prob = pnorm(-.5529 * .75 - .119) - pnorm(-.5529 * .25 - .119); prob
sink("Ma_Yi_HW4_C")
# Quesiton 1. Poisson distribution
# Part a, b, c, f, g are in the pdf file
# Load the data
mydata <- read.csv("hw4.1.csv", header = TRUE)
y <- mydata$y #make it a vector
# Part d
uniquey <- unique(y)
uniquey <- sort(uniquey) #obtain all the values that y can take on
uniquey # there are 12 unique values (from 0 to 11)
prob <- integer(12) #generate a numeric vector of size 12
for (i in 1:12){
prob[i] <- length(y[ which(y == uniquey[i])])/1000
}
prob # a vector of probability each value takes on
# Part e
# (-1) * Empirical expectation of log-likelihood
myfun1 <- function(theta){
result1 <- 0
for (i in 1:12){
result1 <- result1 - prob[i]*(uniquey[i]*log(theta) - theta - log(factorial(uniquey[i])))
}
return(result1)
}
# Empirical log-likelihood for the first observation (y = 5)
myfun2 <- function(theta){
result2 <- prob[6]*(5*log(theta)-theta-log(factorial(5)))
return(result2)
}
# Empirical log-likelihood for the second observation (y = 2)
myfun3 <- function(theta){
result3 <- prob[3]*(2*log(theta)-theta-log(factorial(2)))
return(result3)
}
# Plotting
ellf <- integer(10000) #expected likelihood function
elff <- integer(10000) #likelihood of the first observation
elfs <- integer(10000) # likelihood of the second observation
index <- integer(10000)
for (i in 1:10000){
ellf[i] <- (-1)*myfun1(i/1000) #because it would minimize if we don't use negative one
elff[i] <- myfun2(i/1000)
elfs[i] <- myfun3(i/1000)
index[i] <- i/1000
}
par(mfrow=c(1,3))
plot(index, ellf, main = "Empirical log-likelihood function", xlab = "theta", ylab  ="")
plot(index, elff, main = "Log-likelihood function for the first observation (5)", xlab = "theta", ylab ="", col = "blue")
plot(index, elfs, main = "Log-likelihood function for the second observation (2)", xlab = "theta", ylab ="", col = "red")
# Part h
optimal <- optim(mean(y),myfun1)
optimizer <- optimal$par
optimizer #2.747
mean(y) #2,747
# Question 2. Use the data set grogger.rda to answer the following
library(foreign)
install.packages("lmtest")
library(lmtest)
install.packages("sandwich")
library(sandwich)
# Import the data
load("grogger.rda") #We use load instead of read because it's rda
# Part a
# Create a dummy arr86
grogger$arr86 <- as.numeric(grogger$narr86 %in% c(1:12))
# Linear Probability Model Estimation
lpm <- lm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60, data = grogger)
# Report the result
coeftest(lpm, vcovHC, type = "const")
coeftest(lpm, vcovHC, type = "HC0")
coeftest(lpm, vcov = vcovHC(lpm, type = "const"))
coeftest(lpm, vcov = vcovHC(lpm, type = "HC"))
# vcovHC: A function for extracting the covariance matrix from x is supplied
# const: usual standard errors
# HC: heteroskedasticity-consistent errors
# Save the result as text file
sink("lpm_usual.txt")
print(coeftest(lpm, vcov = vcovHC(lpm, type = "const")))
sink()
sink("lpm_robust.txt")
print(coeftest(lpm, vcoc = vcocHC(lpm, type = "HC")))
sink()
# Comment: Since heteroskedasticity is baked into LPM, use a robust variance-covariance matrix is compulsory.
# Part b
#Test the joint significance of avgsen and tottime
install.packages("aod")
library(aod)
require(stats)
# Select the two variables avgsen and tottime
null <- c(0,0)
testcoef <- as.matrix(rbind(c(0,0,1,0,0,0,0,0,0),c(0,0,0,1,0,0,0,0,0)))
# Wald test and the result as a text file
sink("waldtest_non.txt")
print(wald.test(b = coef(lpm), Sigma = vcovHC(lpm, type = "const"), L = testcoef, H0 = null))
sink() #nonrobust
sink("waldtest_rbst.txt")
print(wald.test(b = coef(lpm), Sigma = vcovHC(lpm, type = "HC"), L = testcoef, H0 = null))
sink() #robust
# Part c
require(aod)
install.packages("mfx")
library(mfx)
# Pobit model and output the result
myprobit <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60, data = grogger)
# Get the coefficient
coeftest(myprobit)
# Get the average
summary(grogger$avgsen)
summary(grogger$tottime)
summary(grogger$ptime86)
summary(grogger$inc86)
# Marginal effects
prob = pnorm(-.5529 * .75 - .119) - pnorm(-.5529 * .25 - .119); prob
sink("myprobit.txt")
print(coeftest(myprobit))
sink()
# Part d
# Generate fitted values
predicted <- fitted(myprobit)
predictedarr <- as.numeric(predicted >= .5)
# Tabulate the fitted values against the actual data and output the result
sink("predicted.txt")
print(table(predictedarr, grogger$arr86))
sink()
# Part e
# New probit model
myprobit2 <- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + born60 + pcnvsq + pt86sq + inc86sq, data = grogger)
# Test for individual significance and output the result
sink("mypobit2.txt")
print(coeftest(myprobit2))
sink()
# Test for joint significance
# Select the three quadratic variables
null2 <- c(0,0,0)
testcoef2 <- as.matrix(rbind(c(0,0,0,0,0,0,0,0,0,1,0,0),
c(0,0,0,0,0,0,0,0,0,0,1,0),
c(0,0,0,0,0,0,0,0,0,0,0,1)))
# Wald test and output the result
sink("waldtest2.txt")
wald.test(b = coef(myprobit2), Sigma = vcovHC(myprobit2, type = "const"), L = testcoef2, H0 = null2)
sink()
sink()
install.packages("lmtest")
smoke
library(wooldridge)
install.packages("wooldridge")
library(wooldridge)
use smoke
smoke
read smoke
load(smoke)
# Import the data
load(smoke.rda)
smoke
# Import the data
load("smoke.rda")
mydata <- smoke
View(mydata)
?smoke
# Import the data
data('smoke')
# Import the data
data("smoke")
mydata <- smoke
View(smoke)
View(mydata)
remove(mydata)
smoke$ledu <- log(edu)
smoke$ledu <- log(smoke$edu)
smoke$edusq <- edu^2
smoke$edusq <- smoke$edu^2
remove(smoke$ledu)
